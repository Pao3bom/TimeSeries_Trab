{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.api import STLForecast\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://archive.ics.uci.edu/static/public/501/beijing+multi+site+air+quality+data.zip -O ./data/data.zip\n",
    "\n",
    "os.makedirs('./data/PRSA_Data', exist_ok=True)\n",
    "\n",
    "!unzip -n ./data/data.zip -d ./data\n",
    "!unzip -n ./data/PRSA2017_Data_20130301-20170228.zip -d data/\n",
    "!mv --no-clobber ./data/PRSA_Data_20130301-20170228/* ./data/PRSA_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path: str, encode_wd: bool=False) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, parse_dates={'timestamp': ['year', 'month', 'day', 'hour']}, date_format=\"%Y %m %d %H\")\n",
    "    df = df.set_index('timestamp')\n",
    "\n",
    "    if encode_wd:\n",
    "        one_hot = pd.get_dummies(df['wd'].fillna('NAN'), dtype=int)\n",
    "        one_hot.loc[one_hot['NAN'] == 1, list(one_hot.columns)] = np.nan\n",
    "        one_hot = one_hot.drop(['NAN'], axis=1)\n",
    "        df = df.join(one_hot)\n",
    "        df = df.drop(['wd'], axis=1)\n",
    "        \n",
    "    df = df.interpolate(method='time')\n",
    "    df = df.interpolate(method='backfill')\n",
    "    df = df.drop(['No'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def visualize_forecasts(full_series: pd.Series, base_forecast: pd.Series, rmse_base: float, triangulation_forecast: pd.Series, rmse_dis:float, column:str, station:str) -> None:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=full_series.index, y=full_series.values, mode='lines', name='Complete Series'))\n",
    "    fig.add_trace(go.Scatter(x=base_forecast.index, y=base_forecast.values, mode='lines', name='Simple Forecast'))\n",
    "    fig.add_trace(go.Scatter(x=triangulation_forecast.index, y=triangulation_forecast.values, mode='lines', name='Triangulation Forecast'))\n",
    "\n",
    "    annotations = []\n",
    "    annotations.append(dict(xref='paper', yref='paper', x=0.5, y=-0.1, xanchor='center', yanchor='top', showarrow=False,\n",
    "                            text=f'Simple Forecast RMSE:   {round(rmse_base, 4)}', font=dict(family='Arial', size=14)))\n",
    "    annotations.append(dict(xref='paper', yref='paper', x=0.5, y=-0.2, xanchor='center', yanchor='top', showarrow=False,\n",
    "                            text=f'Triangulation Forecast RMSE:  {round(rmse_dis, 4)}', font=dict(family='Arial', size=14)))\n",
    "    \n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=f'Forecastings of {column} over time in {station} Air Station (Beijing)'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=dict(\n",
    "                text=f'{column}'\n",
    "            )\n",
    "        ),\n",
    "        annotations=annotations\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "### Goes through 27 combinations of parameters in a simple ARIMA to find the best values\n",
    "def get_best_params(series:pd.Series, division:int, param_grid:dict={'p': [0,1, 2], 'd': [0,1, 2], 'q': [0,1,2 ]}) -> dict:\n",
    "    grid = ParameterGrid(param_grid)\n",
    "    \n",
    "    train_series = series[:-division]\n",
    "    train_series.index = pd.DatetimeIndex(train_series.index.values, freq=train_series.index.inferred_freq)\n",
    "    test_series = series[-division:]\n",
    "\n",
    "    rmse = []\n",
    "\n",
    "    for params in tqdm(grid, total=len(grid)):\n",
    "        model = ARIMA(train_series, order=(params['p'], params['d'], params['q']))\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        pred = model_fit.get_forecast(len(test_series.index))\n",
    "        pred_series = pred.conf_int(alpha = 0.05) \n",
    "        pred_series[\"Predictions\"] = model_fit.predict(start = pred_series.index[0], end = pred_series.index[-1])\n",
    "        pred_series.index = test_series.index\n",
    "        arima_rmse = np.sqrt(mean_squared_error(test_series.values, pred_series[\"Predictions\"]))\n",
    "\n",
    "        rmse.append(arima_rmse)\n",
    "\n",
    "    tuning_results = pd.DataFrame(grid)\n",
    "    tuning_results['rmse'] = rmse\n",
    "    best_params = tuning_results[tuning_results.rmse == tuning_results.rmse.min()].transpose()\n",
    "\n",
    "    return list(best_params.to_dict().values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Based Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = {'Huairou': (116.17, 40.09),\n",
    "'Changping': (116.21, 40.00),\n",
    "'Wanliu': (116.29, 39.98),\n",
    "'Aotizhongxin': (116.40, 39.98),\n",
    "'Gucheng': (116.18, 39.91),\n",
    "'Shunyi': (116.14, 39.82),\n",
    "'Guanyuan': (116.34, 39.92),\n",
    "'Dongsi': (116.42, 39.93),\n",
    "'Tiantan': (116.41, 39.88),\n",
    "'Nongzhanguan': (116.47, 39.93),\n",
    "'Dingling': (116.28, 39.86),\n",
    "'Wanshouxigong': (116.35, 39.88)}\n",
    "\n",
    "def distance_km(coord1: tuple[float, float], coord2: tuple[float, float]) -> float:\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = radians(coord1[0]) \n",
    "    lon1 = radians(coord1[1])\n",
    "    lat2 = radians(coord2[0])\n",
    "    lon2 = radians(coord2[1])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "def get_weights_to_centerpoint(coordinate_dict:dict, centerpoint: str):\n",
    "    distances_dict = {}\n",
    "\n",
    "    for key in coordinate_dict.keys(): ## Loop gets the distances from all other stations to a given centerpoint\n",
    "        if key != centerpoint:\n",
    "            distances_dict[key] = distance_km(coordinate_dict[centerpoint], coordinate_dict[key])\n",
    "\n",
    "    total = sum(distances_dict.values())\n",
    "\n",
    "    weights_dict = {}\n",
    "    for key in distances_dict.keys(): ## Loop calculates a weight inversely proportional to the distance to the centerpoint\n",
    "        weights_dict[key] = total / distances_dict[key]\n",
    "\n",
    "    total_weight = sum(weights_dict.values())\n",
    "    for key in weights_dict.keys(): ## Loop normalizes the weights\n",
    "        weights_dict[key] = weights_dict[key]/total_weight\n",
    "\n",
    "    return weights_dict   \n",
    "    \n",
    "\n",
    "def get_triangulation_forecast(series_dict: dict[pd.Series], division: int, best_params: dict, periodicity:int, coordinate_dict:dict, centerpoint: str):\n",
    "\n",
    "    centerpoint_series = series_dict[centerpoint]\n",
    "    test = centerpoint_series[-division:]\n",
    "\n",
    "    forecasts = {}\n",
    "    for key in tqdm(series_dict.keys(), total=len(series_dict.keys())): ## Loop gets the forecasting predicted for each non-centerpoint station\n",
    "        if key != centerpoint:\n",
    "            train = series_dict[key][:-division]\n",
    "\n",
    "            ### Uses STL to apply seasonality on ARIMA\n",
    "            model = STLForecast(train, ARIMA, model_kwargs={'order':(best_params['p'], best_params['d'], best_params['q'])}, period=periodicity)\n",
    "            model_fit = model.fit()\n",
    "\n",
    "            pred = model_fit.forecast(len(test.index))\n",
    "            pred = pd.Series(pred)\n",
    "            pred.index = test.index\n",
    "\n",
    "\n",
    "            forecasts[key] = np.array(pred)\n",
    "\n",
    "    weights = get_weights_to_centerpoint(coordinate_dict=coordinate_dict, centerpoint=centerpoint)\n",
    "\n",
    "    for key in forecasts.keys(): ## Loop applies the weights to all forecastings\n",
    "        forecasts[key] = forecasts[key] * weights[key]\n",
    "\n",
    "    forecast_matrix = np.array(list(forecasts.values()))\n",
    "    final_forecast = forecast_matrix.sum(axis=0)\n",
    "    \n",
    "    arima_rmse = np.sqrt(mean_squared_error(test.values, final_forecast))\n",
    "    \n",
    "    return pd.Series(final_forecast, index=test.index), arima_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/PRSA_Data'\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "### Amount of hours in other scales\n",
    "day = 24\n",
    "month = 720\n",
    "year = 8760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell finds and stores the best out 27 possible ARIMA parameter combinations for each univariate series in the Dataset\n",
    "\n",
    "if 'bestParams.json' in os.listdir('data/'):\n",
    "    with open('data/bestParams.json', 'r') as f: best_params_dict = json.load(f)\n",
    "else:\n",
    "    df = process_data(f'{path}/{file_list[0]}')\n",
    "    best_params_dict = {}\n",
    "    for column in tqdm(df.columns, total=len(df.columns)):\n",
    "        if column not in ['wd', 'station']:\n",
    "            series = df[column]\n",
    "            best_params = get_best_params(series, division=3*month)\n",
    "            best_params_dict[column] = best_params\n",
    "\n",
    "    with open(\"data/bestParams.json\", 'w') as f: json.dump(best_params_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict.keys() # List the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Control cell for the bellow one\n",
    "# column --------> Defines the univariate series to be explored\n",
    "# centerpoint ---> Defines the Station whose time series will be forecast using both simple forecasting and the novel triangulation forecasting\n",
    "# best_params ---> Gets the best ARIMA parameters for a given univariate series\n",
    "# division ------> Defines the train/test split for the forecast, for example <<year + 3*month>> means that the last 3 months and one year will be forecast and the rest will be used for training]\n",
    "# peridiocity ---> Hyperparameter that defines the period of a series, for example a value of <<year>> means yearly periodicity. Can be set to <<None>>\n",
    "column = 'TEMP' \n",
    "centerpoint = 'Wanliu'\n",
    "best_params = best_params_dict[column]\n",
    "division = year + 3*month\n",
    "periodicity = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### According to the parameters on the cell above calculates simple and triangulation forecast of a given Centerpoint\n",
    "\n",
    "centerpoint_file = [file for file in file_list if centerpoint in file][0]\n",
    "full_series = process_data(f'{path}/{centerpoint_file}')[column]\n",
    "\n",
    "train = full_series[:-division]\n",
    "test = full_series[-division:]\n",
    "\n",
    "### Uses STL to apply seasonality on ARIMA\n",
    "model = STLForecast(train, ARIMA, model_kwargs={'order':(best_params['p'], best_params['d'], best_params['q'])}, period=periodicity)\n",
    "model_fit = model.fit()\n",
    "\n",
    "base_forecast = model_fit.forecast(len(test.index))\n",
    "base_forecast = pd.Series(base_forecast)\n",
    "base_forecast.index = test.index\n",
    "rmse_base = np.sqrt(mean_squared_error(test.values, base_forecast))\n",
    "\n",
    "series_dict = {}\n",
    "for file in file_list:\n",
    "    df = process_data(f'{path}/{file}')\n",
    "    station_name = file.split('_')[2]\n",
    "    series_dict[station_name] = df[column]\n",
    "\n",
    "triangulation_forecast, rmse_dis = get_triangulation_forecast(series_dict, division, best_params, periodicity, coordinate_dict, centerpoint=centerpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_forecasts(full_series, base_forecast=base_forecast, rmse_base=rmse_base, triangulation_forecast=triangulation_forecast, rmse_dis=rmse_dis, column=column, station=centerpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
