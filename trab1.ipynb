{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from aeon.anomaly_detection import KMeansAD, PyODAdapter, DWT_MLEAD\n",
    "from aeon.distances import euclidean_pairwise_distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyod.models.lof import LOF\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://archive.ics.uci.edu/static/public/501/beijing+multi+site+air+quality+data.zip -O ./data/data.zip\n",
    "\n",
    "os.makedirs('./data/PRSA_Data', exist_ok=True)\n",
    "\n",
    "!unzip -n ./data/data.zip -d ./data\n",
    "!unzip -n ./data/PRSA2017_Data_20130301-20170228.zip -d data/\n",
    "!mv --no-clobber ./data/PRSA_Data_20130301-20170228/* ./data/PRSA_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path: str, encode_wd: bool=False) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, parse_dates={'timestamp': ['year', 'month', 'day', 'hour']}, date_format=\"%Y %m %d %H\")\n",
    "    df = df.set_index('timestamp')\n",
    "\n",
    "    if encode_wd:\n",
    "        one_hot = pd.get_dummies(df['wd'].fillna('NAN'), dtype=int)\n",
    "        one_hot.loc[one_hot['NAN'] == 1, list(one_hot.columns)] = np.nan\n",
    "        one_hot = one_hot.drop(['NAN'], axis=1)\n",
    "        df = df.join(one_hot)\n",
    "        df = df.drop(['wd'], axis=1)\n",
    "        \n",
    "    df = df.interpolate(method='time')\n",
    "    df = df.interpolate(method='backfill')\n",
    "    df = df.drop(['No'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_anomalies(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    columns = [column for column in df.columns if column not in['wd', 'station']]\n",
    "    x = np.array(df[columns]).T\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "\n",
    "    anomaly_df = pd.DataFrame({'timestamp':df.index})\n",
    "\n",
    "    detector = KMeansAD(random_state=42)\n",
    "    anomaly_df['anomaly_score_KMeans'] = detector.fit_predict(x)\n",
    "\n",
    "    detector = PyODAdapter(LOF())  \n",
    "    anomaly_df['anomaly_score_PyoD'] = detector.fit_predict(x)\n",
    "\n",
    "    detector = DWT_MLEAD()\n",
    "    for i in range(len(columns)):\n",
    "        anomaly_df[f'anomaly_score_{columns[i]}'] = detector.fit_predict(x[i])\n",
    "\n",
    "\n",
    "    return anomaly_df\n",
    "\n",
    "def get_distances(df_dict: dict, column:str) -> np.ndarray:\n",
    "    arrays = []\n",
    "    for key in df_dict.keys():\n",
    "        arrays.append(np.array(df_dict[key][column]))\n",
    "\n",
    "    arrays = np.array(arrays)\n",
    "\n",
    "    return euclidean_pairwise_distance(arrays), cosine_similarity(arrays)\n",
    "\n",
    "def visualize_scores(df_dict: dict, column:str) -> None:\n",
    "    vis_df = pd.DataFrame({'timestamp': df_dict[list(df_dict.keys())[0]]['timestamp']})\n",
    "\n",
    "    for key in df_dict.keys():\n",
    "        vis_df[key] = df_dict[key][column]\n",
    "\n",
    "    \n",
    "    vis_df = pd.melt(vis_df, ['timestamp'])\n",
    "    names = column.split('_')\n",
    "    title = names[0].capitalize() + ' ' + names[1].capitalize() + ': ' + names[2]\n",
    "    fig = px.line(vis_df, x=\"timestamp\", y=\"value\", color='variable', title=title)\n",
    "    fig.show()\n",
    "\n",
    "def get_whole_city_anomalies(df_dict: dict, column:str) -> pd.DataFrame:\n",
    "\n",
    "    anomaly_df = {}\n",
    "    for key in df_dict.keys():\n",
    "        anomaly_df[key] = np.array(df_dict[key][column])\n",
    "\n",
    "    anomaly_df = pd.DataFrame(anomaly_df)\n",
    "    anomaly_df.index = df_dict[list(df_dict.keys())[0]]['timestamp']\n",
    " \n",
    "    anomalies = anomaly_df[(np.abs(stats.zscore(anomaly_df)) >= 3).all(axis=1)]\n",
    "\n",
    "    return anomalies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/PRSA_Data'\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "os.makedirs('./data/anomalies/', exist_ok=True)\n",
    "anomaly_files = os.listdir('./data/anomalies/')\n",
    "anomaly_dict = {}\n",
    "\n",
    "for file in tqdm(file_list, total=len(file_list)):\n",
    "    station = file.split('_')[2]\n",
    "    if f'{station}.csv' in anomaly_files:\n",
    "        df = pd.read_csv(f'./data/anomalies/{station}.csv', parse_dates=['timestamp'])\n",
    "        df = df[[column for column in df.columns if column != 'Unnamed: 0']]\n",
    "        anomaly_dict[station] = df\n",
    "\n",
    "    else:\n",
    "        df = process_data(f'{path}/{file}')\n",
    "        anomaly_dict[station] = get_anomalies(df)\n",
    "        anomaly_dict[station].to_csv(f'./data/anomalies/{station}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in anomaly_dict['Changping'].columns:\n",
    "    if column != 'timestamp':\n",
    "        euclid, cosine = get_distances(anomaly_dict, column)\n",
    "        print(f'{column} --- Mean Euclid Distance: {round(np.mean(euclid),2)} | Mean Cosine Similarity: {round(100*np.mean(cosine),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in anomaly_dict[list(anomaly_dict.keys())[0]].columns:\n",
    "    if column != 'timestamp':\n",
    "        print(f'{column} --- Whole city anomalies: {get_whole_city_anomalies(anomaly_dict, column).shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scores(anomaly_dict, 'anomaly_score_PRES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_whole_city_anomalies(anomaly_dict, 'anomaly_score_PRES')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
